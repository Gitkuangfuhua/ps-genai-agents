{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Professional Services Retreat | GenAI Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we make a request to an LLM we do so via a prompt. Here we will look at the three main prompts we use in the Text2Cypher application.\n",
    "\n",
    "They include\n",
    "* the agent initialization prompt\n",
    "* The Cypher generation prompt\n",
    "* The Cypher results summarization prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.ps_genai_agents.prompts import create_agent_prompt, create_graphqa_chain_cypher_prompt, create_final_summary_prompt_without_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Initialization Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing an agent, we must pass it a prompt that will define it's behavior. This is the responsibility of the `System Message`. \n",
    "\n",
    "In this prompt template we also have attributes for `chat_history`, `input` and `agent_scratchpad`. \n",
    "\n",
    "We will use `input` to contain the user question.\n",
    "\n",
    "`agent_scratchpad` will contain any processing steps performed.\n",
    "\n",
    "We can optionally use `chat_history` to store the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "          You are a human assistant and you can retrieve survey response information from Neo4j.\n",
      "          Use your tools to answer questions.\n",
      "          If you do not have a tool to answer the question, say so.\n",
      "          If an ID is present in the query, use Text2Cypher.\n",
      "          Do not generate Cypher unless it is via the Text2Cypher tool!\n",
      "          \n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent_prompt = create_agent_prompt()\n",
    "agent_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cypher Generation Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using `LangChain`'s Text2Cypher implementation, we will also use `LangChain`'s [`FewShotPromptTemplate`](https://python.langchain.com/docs/how_to/few_shot_examples/) to structure our Cypher generation prompt. \n",
    "\n",
    "This requires\n",
    "* **prefix**: We place our generation instructions here\n",
    "* **examples**: a list of examples\n",
    "* **example template**: how each example should be formatted\n",
    "* **suffix**: This contains our placeholder for `question`\n",
    "* placeholders for `question` and `schema`\n",
    "\n",
    "We can see that we also declare some sections \n",
    "* `<instructions>...</instructions>`\n",
    "* `<schema>...</schema>`\n",
    "* `<samples>...</samples>`\n",
    "\n",
    "`ps-genai-agents` contains a function that will piece this together for us. We just need to provide the path to the `queries.yml` file.\n",
    "\n",
    "The `question` and `schema` placeholders will be filled by the `Langchain` Text2Cypher class `GraphCypherQAChain` when making a request. We will explain this class more in future notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert Neo4j Cypher translator who understands the question in english and convert to Cypher strictly based on the Neo4j Schema provided and following the instructions below:\n",
      "    <instructions>\n",
      "    * Use aliases to refer the node or relationship in the generated Cypher query\n",
      "    * Generate Cypher query compatible ONLY for Neo4j Version 5\n",
      "    * Do not use EXISTS in the cypher. Use alias when using the WITH keyword\n",
      "    * Only use SIZE when checking the size of a list\n",
      "    * Use only Nodes and relationships mentioned in the schema\n",
      "    * Always enclose the Cypher output inside 3 backticks (```)\n",
      "    * Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Company name use `toLower(c.name) contains 'neo4j'`\n",
      "    * Cypher is NOT SQL. So, do not mix and match the syntaxes\n",
      "    * Only MATCH on the following properties: [\"id\", \"verbatimText\"] unless absolutely necessary.\n",
      "    * Ensure that null results are filtered out before running aggregations!\n",
      "    </instructions>\n",
      "\n",
      "    Strictly use this Schema for Cypher generation:\n",
      "    <schema>\n",
      "    \u001b[33;1m\u001b[1;3m{schema}\u001b[0m\n",
      "    </schema>\n",
      "\n",
      "    The samples below follow the instructions and the schema mentioned above. So, please follow the same when you generate the cypher:\n",
      "    <samples>\n",
      "\n",
      "Human: What is the proportion of male to female complainants about cup holders in the Honda Odyssey?\n",
      "Assistant: MATCH (v:Verbatim {make: \"Honda\", model: \"Odyssey\"})\n",
      "  WHERE v.verbatimText CONTAINS \"cup holder\"\n",
      "WITH SUM(COUNT {MATCH (v:Verbatim) WHERE v.gender = \"Male\" RETURN v}) AS males, \n",
      "     SUM(COUNT {MATCH (v:Verbatim) WHERE v.gender = \"Female\" RETURN v}) AS females\n",
      "RETURN males, females, toFloat(males) / (CASE WHEN females = 0 THEN 1 ELSE females END)  AS maleToFemale\n",
      "\n",
      "Human: What is the proportion of male to female complainants per categories in the Acura RDX?\n",
      "Assistant: MATCH (c:Category)<-[:HAS_CATEGORY]-(v:Verbatim {make: \"Acura\", model: \"RDX\"})\n",
      "WITH c.id AS category,\n",
      "     SUM(COUNT {MATCH (v:Verbatim) WHERE v.gender = \"Male\" RETURN v}) AS males, \n",
      "     SUM(COUNT {MATCH (v:Verbatim) WHERE v.gender = \"Female\" RETURN v}) AS females\n",
      "RETURN category, males, females, toFloat(males) / (CASE WHEN females = 0 THEN 1 ELSE females END) AS maleToFemale \n",
      "ORDER BY category\n",
      "\n",
      "Human: Summarize the top 3 most common complaints about Apple CarPlay on the Honda Pilot.\n",
      "Assistant: MATCH (v:Verbatim {make: \"Honda\", model: \"Pilot\"})\n",
      "  WHERE v.verbatimText CONTAINS \"carplay\"\n",
      "RETURN v.verbatim as content\n",
      "\n",
      "Human: What are the top 10 problems with males between the ages of 40 and 70 years old and what vehicles were involved?\n",
      "Assistant: MATCH (p:Problem)<-[:HAS_PROBLEM]-(v:Verbatim)\n",
      "  WHERE v.minAge >= 40 AND v.maxAge <= 70 AND v.gender = \"Male\"\n",
      "WITH p, COUNT(v) AS total, COLLECT(DISTINCT v.make + \" \" + v.model) AS vehicles\n",
      "ORDER BY total DESC\n",
      "LIMIT 5\n",
      "RETURN p.problem AS problem, total, vehicles\n",
      "\n",
      "Human: What are the top 10 problems that share the most responses between a Honda Odyssey and Honda Civic?\n",
      "Assistant: MATCH (p:Problem)<-[:HAS_PROBLEM]-(v:Verbatim {make: \"Honda\", model: \"Odyssey\"})\n",
      "WITH p, count(v) AS total1\n",
      "MATCH (p)<-[:HAS_PROBLEM]-(v:Verbatim {make: \"Honda\", model: \"Civic\"})\n",
      "WITH p.problem AS problem, total1, count(v) AS total2\n",
      "RETURN problem, total1 + total2 AS totalResponses\n",
      "ORDER BY totalResponses DESC \n",
      "LIMIT 10\n",
      "\n",
      "Human: What are the total responses under seat23 for honda civic, what is the male to female proportion for these responses and what is the problem for seat23?\n",
      "Assistant: MATCH (p:Problem {id: \"SEAT23\"})<-[:HAS_PROBLEM]-(v:Verbatim {make: \"Honda\", model: \"Civic\"})\n",
      "WITH p.problem AS problem, COUNT(v) AS totalResponses, \n",
      "SUM(CASE WHEN v.gender = \"Male\" THEN 1 ELSE 0 END) AS males,\n",
      "SUM(CASE WHEN v.gender = \"Female\" THEN 1 ELSE 0 END) AS females\n",
      "RETURN totalResponses, males, females, toFloat(males) /  (CASE WHEN females = 0 THEN 1 ELSE females END) AS maleToFemaleRatio, problem\n",
      "\n",
      "Human: Compare the sentiment for verbatims related to parking cameras in Acura MDX and Acura RDX.\n",
      "Assistant: MATCH (v:Verbatim) \n",
      "  WHERE v.verbatimText CONTAINS 'acura mdx' AND v.verbatimText CONTAINS 'parking cameras'\n",
      "RETURN v.model AS model, v.verbatim as content LIMIT 50\n",
      "UNION\n",
      "MATCH (v:Verbatim) \n",
      "  WHERE v.verbatimText CONTAINS 'acura rdx' AND v.verbatimText CONTAINS 'parking cameras'\n",
      "RETURN v.model AS model, v.verbatim as content LIMIT 50\n",
      "\n",
      "Human: What are the sentiments towards Honda doors?\n",
      "Assistant: MATCH (v:Verbatim) \n",
      "  WHERE v.verbatimText CONTAINS 'honda' AND v.verbatimText CONTAINS 'door'\n",
      "RETURN v.model AS model, v.verbatim as content\n",
      "\n",
      "Human: For customers who complained about problem DRE10, what other problems are indicated from the same customers? What are top 2 common problems between customers?\n",
      "Assistant: MATCH (p:Problem {id: 'DRE10'})<-[:HAS_PROBLEM]-(v:Verbatim)<-[:SUBMITTED]-(c:Customer)\n",
      "  WHERE v.verbatim <> ''\n",
      "WITH c, p\n",
      "MATCH (c)-[:SUBMITTED]->(v2:Verbatim)-[:HAS_PROBLEM]->(p2:Problem)\n",
      "  WHERE p <> p2 AND v2.verbatim <> ''\n",
      "WITH p.problem AS problem, p2.problem AS similarProblem, COLLECT(v2.verbatim) AS content\n",
      "RETURN problem, similarProblem, content, SIZE(content) AS sharedTotal\n",
      "ORDER BY sharedTotal DESC LIMIT 2;\n",
      "\n",
      "Human: For the infotainment category, what are top 3 models with the highest severity score?\n",
      "Assistant: MATCH (v:Verbatim)\n",
      "  WHERE v.verbatimText CONTAINS 'infotainment' AND v.severity IS NOT NULL\n",
      "RETURN DISTINCT v.model AS model, count(v) AS totalResponses, avg(v.severity) AS score \n",
      "ORDER BY score DESC \n",
      "LIMIT 10;\n",
      "\n",
      "Human: What are the top 3 infotainment problems for each age buckets?\n",
      "Assistant: MATCH (v:Verbatim)-[:HAS_PROBLEM]->(p:Problem)\n",
      "  WHERE v.verbatimText CONTAINS 'infotainment' AND v.ageBucket IS NOT NULL\n",
      "WITH v.ageBucket AS ageBucket, p.problem AS problem, collect(v.verbatim) AS responses\n",
      "WITH ageBucket, problem, size(responses) AS total, responses\n",
      "WITH * ORDER BY ageBucket, total DESC\n",
      "WITH ageBucket, COLLECT(problem) AS problems, COLLECT(total) AS totals, COLLECT(responses) AS responsesList\n",
      "RETURN ageBucket, problems[..3] AS problem, totals[..3] AS total, responsesList[..3] AS reponses\n",
      "LIMIT 3\n",
      "\n",
      "Human: What are the 3 most reported problems for Honda vehicles by model year and what are the 3 most reported problems for Acura vehicles by model year?\n",
      "Assistant: MATCH (v:Verbatim{make: 'Honda'})-[:HAS_PROBLEM]->(p:Problem)\n",
      "WITH v.make AS make, p.problem AS problem, COUNT(v) AS total ORDER BY total DESC LIMIT 3\n",
      "RETURN make, problem, total\n",
      "UNION\n",
      "MATCH (v:Verbatim{make: 'Acura'})-[:HAS_PROBLEM]->(p:Problem)\n",
      "WITH v.make AS make, p.problem AS problem, COUNT(v) AS total ORDER BY total DESC LIMIT 3\n",
      "RETURN make, problem, total;\n",
      "\n",
      "Human: What are the top 5 most severe questions for females aged 30-34 for all Acura models?\n",
      "Assistant: MATCH (q:Question)<-[:HAS_QUESTION]-(v:Verbatim) \n",
      "WHERE v.gender = \"Female\" AND v.make = \"Acura\" AND v.minAge >= 30 AND v.maxAge <= 34 AND v.severity IS NOT NULL\n",
      "WITH q, avg(v.severity) as avgSeverity\n",
      "RETURN q.question AS question, avgSeverity\n",
      "ORDER BY avgSeverity DESC\n",
      "LIMIT 5\n",
      "\n",
      "Human: What are the top 5 most severe problems for females aged 30-34 for all Acura models?\n",
      "Assistant: MATCH (p:Problem)<-[:HAS_PROBLEM]-(v:Verbatim) \n",
      "WHERE v.gender = \"Female\" AND v.make = \"Acura\" AND v.minAge >= 30 AND v.maxAge <= 34 AND v.severity IS NOT NULL\n",
      "WITH p, avg(v.severity) as avgSeverity\n",
      "RETURN p.problem AS problem, avgSeverity\n",
      "ORDER BY avgSeverity DESC\n",
      "LIMIT 5\n",
      "\n",
      "Human: How similar or different are the verbatims for males and females aged 30-34 for all Acura models?\n",
      "Assistant: MATCH (v:Verbatim) \n",
      "WHERE v.gender = \"Male\" AND v.make = \"Acura\" AND v.minAge >= 30 AND v.maxAge <= 34 AND isEmpty(v.verbatim) = false\n",
      "WITH collect(v.verbatim) as content\n",
      "RETURN \"Male\" as gender, content LIMIT 50\n",
      "UNION\n",
      "MATCH (v:Verbatim) \n",
      "WHERE v.gender = \"Female\" AND v.make = \"Acura\" AND v.minAge >= 30 AND v.maxAge <= 34 AND isEmpty(v.verbatim) = false\n",
      "WITH collect(v.verbatim) as content\n",
      "RETURN \"Female\" as gender, content LIMIT 50\n",
      "\n",
      "Human: Please summarize the verbatims for 2023 RDX for question 010 Trunk/TG Touch-Free Sensor DTU and create 5 categories for the problems. As an output, I want a list of verbatims and the corresponding categories\n",
      "Assistant: MATCH (q:Question{id: 10})<-[:HAS_QUESTION]-(v:Verbatim)\n",
      "  WHERE v.model='RDX'\n",
      "RETURN v.verbatim\n",
      "\n",
      "</samples>\n",
      "\n",
      "    Human: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "    Assistant:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "cypher_prompt = create_graphqa_chain_cypher_prompt(\"../../data/iqs/queries/queries.yml\")\n",
    "cypher_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our summarization prompt is responsible for converting the raw Cypher result into something more readable. \n",
    "\n",
    "Here we are using the summarization prompt that will attempt to return results while avoiding a list format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:\n",
      "    Fact: [{'animals': ['dogs', 'cats', 'alligators']}]\n",
      "\n",
      "    * Summarise the above fact as if you are answering this question \"What are some pet options?\"\n",
      "    * When the fact is not empty, assume the question is valid and the answer is true\n",
      "    * Do not return extra text or apologies\n",
      "    * Just return summary to the user. DO NOT start with \"Here is a summary\"\n",
      "    * Don't report empty String results, but include results that are 0 or 0.0.\n",
      "    * Only use bulletpoints to improve readability. Do not just list the provided Facts. Do not ever use more than a FEW bulletpoints.\n",
      "    Assistant:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "result = [{\"animals\": [\"dogs\", \"cats\", \"alligators\"]}]\n",
    "question = \"What are some pet options?\"\n",
    "summarization_prompt = create_final_summary_prompt_without_lists(tool_execution_result=result, question=question)\n",
    "print(summarization_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps-genai-agents-lVTtXIGJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
